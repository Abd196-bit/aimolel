{
  "vocab_size": 32000,
  "d_model": 512,
  "n_heads": 8,
  "n_layers": 6,
  "d_ff": 2048,
  "max_len": 1024,
  "dropout": 0.1,
  "model_name": "DieAI Transformer",
  "version": "1.0",
  "description": "Custom transformer-based language model",
  "capabilities": [
    "text_generation",
    "conversation",
    "search_integration"
  ],
  "training": {
    "batch_size": 4,
    "learning_rate": 1e-4,
    "weight_decay": 0.01,
    "warmup_steps": 1000,
    "max_grad_norm": 1.0
  },
  "inference": {
    "max_length": 512,
    "temperature": 0.8,
    "top_k": 50,
    "top_p": 0.95,
    "repetition_penalty": 1.1
  }
}
